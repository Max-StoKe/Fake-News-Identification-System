# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t5XC4ntGpcNbRGrfubsrp-fjP5pNvqLl
"""

import requests
import pandas as pd
import bs4
import sqlite3
import csv
import matplotlib.pyplot as plt

# ===================== çˆ¬èŸ²å‡½å¼ ===================== #
def crawler():
    global news_data

    dateTag = objSoup.find_all("div", class_="wp-block-kadence-advancedheading")
    dynamic_blocks = objSoup.find_all("div", class_="wp-block-kadence-dynamichtml")

    titles, contents = [], []
    current_title = None

    # æŒ‰ç…§ HTML é †åºé…å°æ¨™é¡Œèˆ‡å…§å®¹
    for block in dynamic_blocks:
        cls = " ".join(block.get("class", []))
        text = block.get_text(strip=True)
        if "_5a54c2-26" in cls:  # æ¨™é¡Œ
            current_title = text
        elif "_eab4c7-ca" in cls and current_title:  # å…§å®¹
            titles.append(current_title)
            contents.append(text)
            current_title = None

    # æ—¥æœŸæ•¸é‡å¯èƒ½ä¸åŒï¼Œå–æœ€çŸ­é•·åº¦
    min_len = min(len(titles), len(contents), len(dateTag))

    news_data = []
    for i in range(min_len):
        date_text = dateTag[i].get_text(strip=True) if i < len(dateTag) else ""
        news_data.append({
            "Title": titles[i],
            "Text": contents[i],
            "Date": date_text
        })

    print(f"âœ… å·²ä½¿ç”¨çˆ¬èŸ²å–å¾—è³‡æ–™ï¼Œå…± {len(news_data)} ç­†ã€‚")


# ===================== åŒ¯å‡º CSV ===================== #
def toCSV():
    global csvFile
    if not news_data:
        print("âŒ æ²’æœ‰è³‡æ–™å¯å„²å­˜ï¼Œè«‹å…ˆåŸ·è¡Œçˆ¬èŸ²ï¼ˆé¸é …1ï¼‰")
        return

    csvFile = pd.DataFrame(news_data)
    csvFile.to_csv('News.csv', encoding='utf_8_sig', index=False)
    print(f"âœ… å·²æŠŠçˆ¬èŸ²è³‡æ–™å„²å­˜ç‚º News.csvï¼Œå…± {len(csvFile)} ç­†ã€‚")


# ===================== é¡¯ç¤ºçˆ¬èŸ²çµæœ ===================== #
def print_text():
    count = min(len(news_data), 10)
    for i in range(count):
        print("\näº‹å¯¦æŸ¥æ ¸å ±å‘Š:", news_data[i]["Title"])
        print("\nå…§å®¹:", news_data[i]["Text"])
        print("\næ—¥æœŸ:", news_data[i]["Date"])
        print("========================================================================================")


# ===================== é¡¯ç¤º CSV ===================== #
def printCSV():
    print(csvFile)


# ===================== æŸ¥è©¢è³‡æ–™åº« ===================== #
def load_Data():
    print("\næŸ¥è©¢è³‡æ–™åº«è£çš„è³‡æ–™")
    results = conn.execute("SELECT * FROM News")
    for record in results:
        print("========================================================================================")
        print("Index =", record[0])
        print("\næ¨™é¡Œ =", record[1])
        print("\nå…§å®¹ =", record[2])
        print("\næ—¥æœŸ =", record[3])


# ===================== åˆªé™¤è³‡æ–™åº« ===================== #
def delete_sql():
    sql = '''DROP TABLE IF EXISTS News'''
    conn.execute(sql)
    sql = '''CREATE TABLE News(IndexNum INT, Title TEXT, Text TEXT, Date TEXT)'''
    conn.execute(sql)
    print("âœ… å·²åˆªé™¤è³‡æ–™åº«è£çš„è³‡æ–™ï¼ˆä¸¦é‡å»ºç©ºè¡¨ï¼‰")


# ===================== æ›´æ–°è³‡æ–™åº« ===================== #
def updateDB():
    fn = 'News.csv'
    try:
        with open(fn, encoding="utf-8") as csvFile:
            csvReader = csv.reader(csvFile)
            listCsv = list(csvReader)
            # Assuming the first row is a header, skip it
            csvData = listCsv[1:]
            for i, row in enumerate(csvData): # Add enumerate to generate IndexNum
                # The CSV has Title, Text, Date (3 columns) because index=False was used in to_csv
                # The database expects IndexNum, Title, Text, Date (4 columns)
                IndexSQL = i + 1 # Generate a 1-based index
                titleSQL = row[0]
                textSQL = row[1]
                dateSQL = row[2]
                x = (IndexSQL, titleSQL, textSQL, dateSQL)
                sql = '''INSERT INTO News(IndexNum, Title, Text, Date) VALUES(?,?,?,?)'''
                conn.execute(sql, x)
                conn.commit()
            print("âœ… å·²æ›´æ–°è³‡æ–™åº«ï¼Œå…±", len(csvData), "ç­†ã€‚")
    except FileNotFoundError:
        print("âŒ æ‰¾ä¸åˆ° News.csvï¼Œè«‹å…ˆåŸ·è¡Œé¸é …3 å„²å­˜CSVã€‚")
    except IndexError as e:
        print(f"âŒ éŒ¯èª¤ï¼CSVæª”æ¡ˆæ ¼å¼ä¸æ­£ç¢ºï¼Œé æœŸæ¯è¡Œæœ‰è‡³å°‘3æ¬„è³‡æ–™(Title, Text, Date)ã€‚è©³ç´°éŒ¯èª¤: {e}")
        print(f"å•é¡Œç™¼ç”Ÿçš„è¡Œ: {row}")
    except Exception as e:
        print(f"âŒ æ›´æ–°è³‡æ–™åº«æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {e}")


# ===================== é—œé–‰è³‡æ–™åº« ===================== #
def closeDB():
    conn.close()
    print("âœ… å·²é—œé–‰è³‡æ–™åº«é€£ç·šã€‚")


# ===================== ä¸»ç¨‹å¼ ===================== #
conn = sqlite3.connect("Group.db")
conn.execute('PRAGMA encoding="UTF-8";')

news_data = []

url = 'https://tfc-taiwan.org.tw/articles/report'
response = requests.get(url)
response.encoding = 'utf-8'
objSoup = bs4.BeautifulSoup(response.text, 'lxml')

while True:
    print("\n====================== å‡æ–°èåˆ¤æ–·ç³»çµ± ========================")
    print("1. çˆ¬èŸ²å°ç£äº‹å¯¦æŸ¥æ ¸ä¸­å¿ƒçš„è³‡æ–™")
    print("2. é¡¯ç¤ºçˆ¬èŸ²çš„è³‡æ–™")
    print("3. å„²å­˜çˆ¬èŸ²è³‡æ–™ç‚º CSV æª”")
    print("4. é¡¯ç¤º News.csv çš„è³‡æ–™")
    print("5. åˆªé™¤è³‡æ–™åº«è£ç¾æœ‰çš„è³‡æ–™")
    print("6. æ›´æ–°è³‡æ–™åº«è£çš„è³‡æ–™")
    print("7. æŸ¥è©¢è³‡æ–™åº«è£çš„è³‡æ–™")
    print("8. Exit")
    print("=============================================================")
    try:
        menu_input = int(input("\nè«‹é¸æ“‡è¦ä½¿ç”¨çš„åŠŸèƒ½ (1~8): "))
    except ValueError:
        print("âŒ è«‹è¼¸å…¥æ•¸å­— 1~8")
        continue

    if menu_input == 1:
        crawler()

    elif menu_input == 2:
        if news_data:
            print_text()
        else:
            print("âŒ å°šæœªçˆ¬å–è³‡æ–™ï¼Œè«‹å…ˆé¸æ“‡ 1")

    elif menu_input == 3:
        toCSV()

    elif menu_input == 4:
        try:
            printCSV()
        except NameError:
            print("âŒ Error! éœ€å…ˆå„²å­˜ç‚º CSV æª” (é¸é …3)")

    elif menu_input == 5:
        delete_sql()

    elif menu_input == 6:
        updateDB()

    elif menu_input == 7:
        try:
            load_Data()
        except Exception as e:
            print("âŒ Error! æŸ¥è©¢è³‡æ–™åº«å¤±æ•—")
            print("è©³ç´°éŒ¯èª¤:", e)

    elif menu_input == 8:
        closeDB()
        print("ğŸ‘‹ Exit")
        break

    else:
        print("âŒ è«‹è¼¸å…¥ 1~8 ä¹‹é–“çš„æ•¸å­—")