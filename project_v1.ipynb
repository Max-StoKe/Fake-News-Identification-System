{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed02206c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================假新聞判斷系統========================\n",
      "1.爬蟲台灣事實查核中心的資料\n",
      "2.輸出爬蟲的資料\n",
      "3.把爬蟲資料儲存為CSV檔\n",
      "4.輸出News.csv裏的資料\n",
      "5.刪除資料庫裏現有的資料\n",
      "6.更新資料庫裏的資料\n",
      "7.查詢資料庫裏的資料\n",
      "8.Exit\n",
      "=============================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 105\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m8.Exit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=============================================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 105\u001b[0m menu_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m請選擇要使用的功能(1~8) :\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m menu_input\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    108\u001b[0m     crawler()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py:1175\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[0;32m   1172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[0;32m   1173\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1174\u001b[0m     )\n\u001b[1;32m-> 1175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel\\kernelbase.py:1217\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1216\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m-> 1217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import bs4\n",
    "import sqlite3\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def crawler():\n",
    "    global dateTag\n",
    "    global textTag\n",
    "    global titleTag \n",
    "    \n",
    "    dateTag = objSoup.select('div.post-date')\n",
    "    textTag = objSoup.select('div.entity-list-body')\n",
    "    #ContentEle=objSoup.select(\"div.view-content\")\n",
    "    titleTag=objSoup.find_all('h3',class_=\"entity-list-title\")\n",
    "    print(\"已使用爬蟲取得資料\")\n",
    "def toCSV():\n",
    "    global csvFile\n",
    "    for title in titleTag:\n",
    "        content.append(title.get_text())\n",
    "    #for text in objSoup.find_all('div',class_=\"entity-list-body\"):    \n",
    "    for textTemp in textTag: \n",
    "        text_Store.append(textTemp.text)\n",
    "        if len(text_Store)>=10:\n",
    "            break\n",
    "    #for date in objSoup.find_all('div',class_=\"post-date\"):    \n",
    "    for date in dateTag:    \n",
    "        date_Store.append(date.text)  \n",
    "    addTag ={'Title':content,'Text':text_Store,'Date':date_Store}\n",
    "    csvFile = pd.DataFrame(addTag)\n",
    "    csvFile.to_csv('News.csv',encoding='utf_8_sig')\n",
    "    print(\"已把爬蟲資料儲存為News.csv\")\n",
    "    \n",
    "def printCSV():\n",
    "    print(csvFile)\n",
    "def print_text(): \n",
    "    for i in range(0,10):\n",
    "        print(\"\\n事實查核報告: \" + titleTag[i].text)# 列出標題\n",
    "        print(\"\\n\",textTag[i].text) # 列出内容\n",
    "        print(\"\\n\",dateTag[i].text) # 列出日期\n",
    "        print(\"========================================================================================\")\n",
    "        \n",
    "def load_Data():\n",
    "    print(\"\\n查詢資料庫裏的資料\")\n",
    "    results = conn.execute(\"SELECT * from News\")\n",
    "    for record in results:\n",
    "        print(\"========================================================================================\")\n",
    "        print(\"Index = \", record[0])\n",
    "        print(\"\\n標題 = \", record[1])\n",
    "        print(\"\\n内容 = \", record[2])\n",
    "        print(\"\\n日期 = \", record[3])\n",
    "        \n",
    "\n",
    "def delete_sql():\n",
    "    sql = '''DROP TABLE IF EXISTS News'''    \n",
    "    conn.execute(sql)  \n",
    "    sql = '''Create table News(IndexNum int,Title text,Text text,Date text)'''\n",
    "    conn.execute(sql)   \n",
    "    print(\"已刪除資料庫裏的資料\")\n",
    "def updateDB():\n",
    "    fn = 'News.csv'\n",
    "    with open(fn,encoding=\"utf-8\") as csvFile: # 儲存在SQLite\n",
    "        csvReader = csv.reader(csvFile)\n",
    "        listCsv = list(csvReader) # 轉成串列\n",
    "        csvData = listCsv[1:]  # 切片刪除前1 rows\n",
    "        for row in csvData:\n",
    "            IndexSQL = row[0] # index\n",
    "            titleSQL = row[1] # 標題\n",
    "            textSQL = row[2]  #内容\n",
    "            dateSQL = row[3] # 日期\n",
    "            x = (IndexSQL,titleSQL,textSQL, dateSQL)\n",
    "            sql = '''insert into News(IndexNum,Title,Text,Date) values(?,?,?,?)'''\n",
    "            conn.execute(sql,x)\n",
    "            conn.commit()\n",
    "        print(\"已更新資料庫裏的資料\")\n",
    "def closeDB():\n",
    "    conn.close() # 關閉資料庫連線\n",
    "#===================================Main=================================================================    \n",
    "conn = sqlite3.connect(\"Group.db\")\n",
    "conn.execute('PRAGMA encoding=\"UTF-8\";')\n",
    "\n",
    "date_Store = []\n",
    "text_Store = []\n",
    "content = []\n",
    "\n",
    "response = requests.get('https://tfc-taiwan.org.tw/articles/report')\n",
    "response.encoding='utf-8'\n",
    "\n",
    "objSoup = bs4.BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "\n",
    "while True:\n",
    "    print(\"\\n======================假新聞判斷系統========================\")\n",
    "    print(\"1.爬蟲台灣事實查核中心的資料\")\n",
    "    print(\"2.輸出爬蟲的資料\")\n",
    "    print(\"3.把爬蟲資料儲存為CSV檔\")\n",
    "    print(\"4.輸出News.csv裏的資料\")\n",
    "    print(\"5.刪除資料庫裏現有的資料\")\n",
    "    print(\"6.更新資料庫裏的資料\")\n",
    "    print(\"7.查詢資料庫裏的資料\")\n",
    "    print(\"8.Exit\")\n",
    "    print(\"=============================================================\")\n",
    "    menu_input = int(input(\"\\n請選擇要使用的功能(1~8) :\"))\n",
    "    if menu_input==1:\n",
    "        \n",
    "        crawler()\n",
    "        \n",
    "    elif menu_input==2:\n",
    "        try:\n",
    "            print_text()\n",
    "        except:\n",
    "            print(\"Error!,需先用爬蟲取得資料(選項1)\")\n",
    "            \n",
    "    elif menu_input==3:\n",
    "        try:\n",
    "            toCSV()\n",
    "        except:\n",
    "            print(\"Error!,需先用爬蟲取得資料(選項1)\")\n",
    "            \n",
    "    elif menu_input==4:\n",
    "        try:\n",
    "            printCSV()\n",
    "        except:\n",
    "            print(\"Error!,需先把爬蟲資料儲存為CSV檔(選項3)\")\n",
    "            \n",
    "    elif menu_input==5:\n",
    "        delete_sql()\n",
    "    \n",
    "    elif menu_input==6:\n",
    "        try:\n",
    "            updateDB()\n",
    "        except:\n",
    "            print(\"Error!,需先把爬蟲資料儲存為CSV檔(選項3)\")\n",
    "            \n",
    "    elif menu_input==7:\n",
    "        try:\n",
    "            load_Data()\n",
    "        except:\n",
    "            print(\"Error!,需先把爬蟲資料儲存為CSV檔(選項3)\")\n",
    "            \n",
    "    elif menu_input==8:\n",
    "        closeDB()\n",
    "        print(\"Exit\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de12a39f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
